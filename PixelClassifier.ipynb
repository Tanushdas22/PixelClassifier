{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05629eb8",
      "metadata": {
        "id": "05629eb8"
      },
      "source": [
        "\n",
        "# PixelClassifier – LeNet style CNN (MNIST)\n",
        "\n",
        "### Objective\n",
        "In this notebook, I implement a simple LeNet-style Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. I perform **5-fold Stratified Cross-Validation** using fixed hyperparameters and retrain the best-performing model on the full training set to evaluate its test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66711ce5",
      "metadata": {
        "id": "66711ce5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import core libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, utils, optimizers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16db52f8",
      "metadata": {
        "id": "16db52f8"
      },
      "source": [
        "\n",
        "## Loading and Preprocessing the MNIST Dataset\n",
        "I load the MNIST dataset directly from Keras.  \n",
        "Images are reshaped to include a single grayscale channel and normalized to [0, 1] for stable training.  \n",
        "Labels are integer-encoded here and will be one-hot encoded **within each fold** to save memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f613d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43f613d0",
        "outputId": "f2b41968-a52f-4b31-e7ab-a8091fad4c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28, 1)\n",
            "Test data shape: (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "num_classes = 10\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31c4b5c",
      "metadata": {
        "id": "d31c4b5c"
      },
      "source": [
        "\n",
        "## Defining the CNN Model (LeNet-style)\n",
        "I designed a simple CNN that follows the classic LeNet structure:\n",
        "- Two convolutional + pooling layers\n",
        "- One dense hidden layer\n",
        "- A softmax output layer\n",
        "\n",
        "I use fixed hyperparameters: 32 filters, kernel size (3,3), learning rate 0.001, and dense layer size 128.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ca52fe",
      "metadata": {
        "id": "21ca52fe"
      },
      "outputs": [],
      "source": [
        "def build_lenet(filters, learning_rate):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(filters, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(filters * 2, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c39ced",
      "metadata": {
        "id": "a1c39ced"
      },
      "source": [
        "\n",
        "## 5-Fold Stratified Cross-Validation\n",
        "I split the dataset into five folds using `StratifiedKFold`.  \n",
        "For each fold, a new CNN model is trained for **3 epochs** using one-hot encoded labels.  \n",
        "After training, I record the validation accuracy for each fold and compute the mean performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb9101c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abb9101c",
        "outputId": "e881ff76-ff43-4584-d2a1-78abb8ecd0a2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hyperparameter combination: filters = 16, learning rate = 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "  Fold 1 accuracy = 0.9835\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 2 accuracy = 0.9827\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 3 accuracy = 0.9826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 4 accuracy = 0.9804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 5 accuracy = 0.9814\n",
            "Average accuracy = 0.9821\n",
            "\n",
            "Hyperparameter combination: filters = 16, learning rate = 0.01\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 1 accuracy = 0.9827\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 2 accuracy = 0.9815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 3 accuracy = 0.9869\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 4 accuracy = 0.9823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "  Fold 5 accuracy = 0.9758\n",
            "Average accuracy = 0.9819\n",
            "\n",
            "Hyperparameter combination: filters = 32, learning rate = 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 1 accuracy = 0.9876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 2 accuracy = 0.9858\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step\n",
            "  Fold 3 accuracy = 0.9858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 4 accuracy = 0.9834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 5 accuracy = 0.9826\n",
            "Average accuracy = 0.9850\n",
            "\n",
            "Hyperparameter combination: filters = 32, learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 1 accuracy = 0.9853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 2 accuracy = 0.9831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "  Fold 3 accuracy = 0.9820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step\n",
            "  Fold 4 accuracy = 0.9812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "  Fold 5 accuracy = 0.9757\n",
            "Average accuracy = 0.9815\n"
          ]
        }
      ],
      "source": [
        "param_combinations = [\n",
        "    {'filters': 16, 'lr': 0.001},\n",
        "    {'filters': 16, 'lr': 0.01},\n",
        "    {'filters': 32, 'lr': 0.001},\n",
        "    {'filters': 32, 'lr': 0.01}\n",
        "]\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "results = []\n",
        "\n",
        "for params in param_combinations:\n",
        "    filters = params['filters']\n",
        "    lr = params['lr']\n",
        "    print(f\"\\nHyperparameter combination: filters = {filters}, learning rate = {lr}\")\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(x_train, y_train), 1):\n",
        "        # Split and encode\n",
        "        X_train_fold, X_val_fold = x_train[train_idx], x_train[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "        y_train_fold_oh = utils.to_categorical(y_train_fold, num_classes)\n",
        "        y_val_fold_oh = utils.to_categorical(y_val_fold, num_classes)\n",
        "\n",
        "        # Build model\n",
        "        model = build_lenet(filters, lr)\n",
        "        model.fit(X_train_fold, y_train_fold_oh, epochs=3, batch_size=128,\n",
        "                  validation_data=(X_val_fold, y_val_fold_oh), verbose=0)\n",
        "\n",
        "        # Evaluate accuracy\n",
        "        val_preds = np.argmax(model.predict(X_val_fold), axis=1)\n",
        "        fold_acc = accuracy_score(y_val_fold, val_preds)\n",
        "        fold_accuracies.append(fold_acc)\n",
        "        print(f\"  Fold {fold} accuracy = {fold_acc:.4f}\")\n",
        "\n",
        "    avg_acc = np.mean(fold_accuracies)\n",
        "    results.append({'filters': filters, 'lr': lr, 'mean_acc': avg_acc})\n",
        "    print(f\"Average accuracy = {avg_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b770d577",
      "metadata": {
        "id": "b770d577"
      },
      "source": [
        "\n",
        "## Selecting the Best Hyperparameter Combination and Retraining\n",
        "After all combinations have been tested, I identify the one with the highest mean validation accuracy.  \n",
        "Then I retrain the model using that configuration on the **entire training dataset** for 3 epochs and report final test accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1be397b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1be397b",
        "outputId": "ddcb4b3d-42b4-401f-ea87-7a8f9882e2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best hyperparameters found:\n",
            "{'filters': 32, 'lr': 0.001, 'mean_acc': np.float64(0.9850166666666667)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - accuracy: 0.8565 - loss: 0.4845\n",
            "Epoch 2/3\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9805 - loss: 0.0606\n",
            "Epoch 3/3\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - accuracy: 0.9870 - loss: 0.0409\n",
            "\n",
            "Final Test Accuracy: 0.9868\n"
          ]
        }
      ],
      "source": [
        "best_params = max(results, key=lambda x: x['mean_acc'])\n",
        "print(\"\\nBest hyperparameters found:\")\n",
        "print(best_params)\n",
        "\n",
        "# One-hot encode full dataset\n",
        "y_train_oh = utils.to_categorical(y_train, num_classes)\n",
        "y_test_oh = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Retrain best model on full training data\n",
        "final_model = build_lenet(best_params['filters'], best_params['lr'])\n",
        "final_model.fit(x_train, y_train_oh, epochs=3, batch_size=128, verbose=1)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = final_model.evaluate(x_test, y_test_oh, verbose=0)\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0ab95a",
      "metadata": {
        "id": "de0ab95a"
      },
      "source": [
        "# Final Report\n",
        "\n",
        "## 1. Dataset and Preparation\n",
        "\n",
        "For this lab, I used the MNIST dataset, which consists of 70,000 grayscale images of handwritten digits (0–9). Each image is 28×28 pixels in size. The dataset is split into 60,000 training samples and 10,000 test samples.\n",
        "\n",
        "Before training, I normalized all pixel values by dividing them by 255 so that they fall in the range [0, 1]. This normalization helps the model converge faster. Each image was reshaped to include a single channel, resulting in an input shape of (28, 28, 1). The class labels were one-hot encoded within each fold of the cross-validation loop to ensure efficient memory usage and proper label formatting for categorical cross-entropy.\n",
        "\n",
        "\n",
        "## 2. CNN Model Architecture\n",
        "\n",
        "The model implemented in this lab follows a simplified LeNet-style CNN structure that is lightweight yet expressive enough for MNIST. The layer sequence is as follows:\n",
        "\n",
        "Input → Conv2D (ReLU) → MaxPooling2D → Conv2D (ReLU) → MaxPooling2D → Flatten → Dense (ReLU) → Dense (Softmax)\n",
        "\n",
        "- The first convolutional layer extracts local spatial features using a 3×3 kernel.  \n",
        "- The max-pooling layer reduces feature map dimensions and adds translation invariance.  \n",
        "- A second convolution–pool block increases feature depth for stronger representations.  \n",
        "- The Flatten layer converts the 2D feature maps into a 1D vector.  \n",
        "- This is followed by a Dense layer with 128 units (ReLU activation), and finally a Dense output layer with 10 neurons (Softmax) for classification.\n",
        "\n",
        "The architecture is deliberately compact to keep computation time short while maintaining high accuracy. It reflects the same design principles as LeNet, but with minor updates like the use of Adam as the optimizer.\n",
        "\n",
        "## 3. Hyperparameter Exploration\n",
        "\n",
        "To analyze the impact of network capacity and learning rate, I evaluated four fixed hyperparameter configurations using 5-fold Stratified Cross-Validation. Each configuration combined:\n",
        "\n",
        "- Filters: {16, 32}  \n",
        "- Learning rate: {0.001, 0.01}  \n",
        "\n",
        "Each fold was trained for 3 epochs, balancing speed with sufficient convergence.\n",
        "\n",
        "The configurations tested were:\n",
        "\n",
        "| Filters | Learning Rate |\n",
        "|:--------:|:--------------:|\n",
        "| 16 | 0.001 |\n",
        "| 16 | 0.01  |\n",
        "| 32 | 0.001 |\n",
        "| 32 | 0.01  |\n",
        "\n",
        "## 4. Results and Evaluation\n",
        "\n",
        "The mean accuracies across folds for each configuration were:\n",
        "\n",
        "| Filters | Learning Rate | Mean Accuracy |\n",
        "|:--------:|:--------------:|:--------------:|\n",
        "| 16 | 0.001 | 0.9821 |\n",
        "| 16 | 0.01  | 0.9819 |\n",
        "| 32 | 0.001 | **0.9850** |\n",
        "| 32 | 0.01  | 0.9815 |\n",
        "\n",
        "Based on these results, the best-performing combination was:\n",
        "> filters = 32, learning rate = 0.001\n",
        "\n",
        "This configuration achieved a mean validation accuracy of 98.5% across folds.\n",
        "\n",
        "I then retrained this configuration on the full 60,000-image training set for 3 epochs and evaluated it on the 10,000-image test set. The model achieved a final test accuracy of 98.68%, which is an excellent result for a lightweight CNN trained in under a few minutes.\n",
        "\n",
        "## 5. Discussion\n",
        "\n",
        "This experiment shows that even a relatively simple CNN can reach near state-of-the-art accuracy on MNIST without deep architectures or long training times.  For context, deeper models trained with more epochs (20–50) or additional regularization such as dropout and batch normalization can reach 99.2–99.4% accuracy. However, given that my model was trained for just 3 epochs with only two convolutional layers, achieving 98.68% demonstrates strong generalization and efficiency.\n",
        "\n",
        "Some ways the accuracy could be further improved include:\n",
        "- Adding another convolution–pool block for more feature extraction.\n",
        "- Increasing training epochs.\n",
        "- Introducing small data augmentations to improve robustness.\n",
        "- Trying batch normalization or dropout to reduce minor overfitting.\n",
        "\n",
        "## 6. Conclusion\n",
        "\n",
        "Through this lab, I successfully implemented and evaluated a compact LeNet-style CNN on the MNIST dataset using 5-fold Stratified Cross-Validation.\n",
        "The best-performing configuration (filters = 32, learning rate = 0.001) produced a final test accuracy of 98.68% after retraining on the full dataset.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##References\n",
        "\n",
        "[1] Yann LeCun, Léon Bottou, Yoshua Bengio and Patrick Haffner: Gradient Based Learning Applied to Document Recognition, Proceedings of IEEE, 86(11):2278–2324, 1998\n",
        "\n",
        "[2] Keras Conv2D and Convolutional Layers (https://pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/)\n",
        "\n",
        "[3] Convolutional Neural Network (CNN) (https://blog.gopenai.com/convolutional-neural-network-cnn-054ac70d40ec)"
      ],
      "metadata": {
        "id": "MiAXgQ-RBJDy"
      },
      "id": "MiAXgQ-RBJDy"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
